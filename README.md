# ai-foundation-project
Using TinyLlama test data struction and performation.

# AI Foundation Project â€“ LLM & ComfyUI Starter

æœ¬å°ˆæ¡ˆåŒæ™‚æä¾› **Jupyter ç­†è¨˜ï¼ˆæ•™å­¸/å±•ç¤ºï¼‰** èˆ‡ **æ¨¡çµ„åŒ– Python ç¨‹å¼ï¼ˆé‡ç”¨/å°ˆæ¡ˆåŒ–ï¼‰**ï¼š
- `notebooks/`ï¼šå¾ tokenizer â†’ dict/tensor â†’ generate â†’ decode çš„é€æ­¥ç­†è¨˜ï¼Œå« GPU/CPU åŸºæº–æ¸¬è©¦èˆ‡ ComfyUI workflow æˆªåœ–ã€‚
- `src/`ï¼šå°è£è¼‰å…¥æ¨¡å‹ã€å°è©±ç”Ÿæˆã€å¯è¦–åŒ–ç­‰å¸¸ç”¨å‡½å¼ï¼Œæ–¹ä¾¿åœ¨ notebook èˆ‡è…³æœ¬é–“é‡ç”¨ã€‚

## âœ¨ Features
- TinyLlama / Qwen / Mistral çš„æœ€å°å¯è¡Œæ¨ç†æµç¨‹
- Chat templateï¼ˆHF `apply_chat_template`ï¼‰æ­£ç¢ºç”¨æ³•
- GPU vs CPU çŸ©é™£ä¹˜æ³•/æ¨ç†å°å‹ benchmark
- å¯é‡ç¾çš„å¯¦é©—çµæ§‹ï¼ˆconfigs / logs å¯é¸ï¼‰

## ğŸš€ Quickstart
```bash
# 1) å»ºè­°ä½¿ç”¨ conda ç’°å¢ƒ
conda create -n ai-core python=3.11 -y
conda activate ai-core

# 2) å®‰è£å¥—ä»¶
pip install -r requirements.txt

# 3) è·‘æœ€å°æ¸¬è©¦ï¼ˆTinyLlama ç”Ÿæˆï¼‰
python - << 'PY'
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
mid = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
tok = AutoTokenizer.from_pretrained(mid)
model = AutoModelForCausalLM.from_pretrained(mid, device_map="auto")
messages = [
    {"role":"system","content":"You are an intelligent AI assistant."},
    {"role":"user","content":"Say hi in one short sentence."}
]
prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
enc = tok(prompt, return_tensors="pt").to(model.device)
with torch.no_grad():
    out = model.generate(**enc, max_new_tokens=40)
print(tok.decode(out[0], skip_special_tokens=True))
PY


## ğŸ“¦ å°ˆæ¡ˆçµæ§‹
<details>
<summary>å±•é–‹çµæ§‹æ¨¹</summary>
ai-foundation-project/
â”œâ”€ notebooks/
â”‚ â”œâ”€ 01_tokenizer_intro.ipynb
â”‚ â”œâ”€ 02_tinyllama_chat_template.ipynb
â”‚ â””â”€ 03_bench_gpu_vs_cpu.ipynb
â”œâ”€ src/
â”‚ â”œâ”€ init.py
â”‚ â”œâ”€ dataio.py
â”‚ â”œâ”€ modeling.py
â”‚ â”œâ”€ chat_utils.py
â”‚ â””â”€ viz.py
â”œâ”€ experiments/
â”‚ â”œâ”€ configs/
â”‚ â””â”€ logs/
â”œâ”€ tests/
â”‚ â””â”€ test_tokenize.py
â”œâ”€ assets/
â”‚ â”œâ”€ comfy_workflow.png
â”‚ â”œâ”€ demo_generation.png
â”‚ â””â”€ cover.png
â”œâ”€ .gitignore
â”œâ”€ .gitattributes
â”œâ”€ requirements.txt
â”œâ”€ README.md
â””â”€ LICENSE
</details>

## ğŸš€ å¿«é€Ÿé–‹å§‹
```bash
# 1) å»ºè­°ä½¿ç”¨ conda
conda create -n ai-core python=3.11 -y && conda activate ai-core

# 2) å®‰è£å¥—ä»¶
pip install -r requirements.txt